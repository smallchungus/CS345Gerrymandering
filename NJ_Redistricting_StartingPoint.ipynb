{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3d493-83fb-4965-bdcb-f1054425e86e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install geojson\n",
    "!pip install shapely\n",
    "!pip install PyShp\n",
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a7f250-1f24-4f02-832b-1df2dceaa50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import csv\n",
    "import ast\n",
    "import shapefile as shp\n",
    "from shapely.geometry import Polygon,shape,MultiPolygon\n",
    "import shapely.ops\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1549e7-0856-443a-aedc-df06d9caf33a",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28b0c5-f5b6-4baf-9295-07dbff55df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDistrictContiguous(district_num, assignment, contiguity_list, print_isolates=False, ignore_list=[]):\n",
    "    ## input:\n",
    "    ## district_num: the district number\n",
    "    ## assignment: the assignment from precinct to district\n",
    "    ## contiguity_list: the list of neighbors for each precinct, from the csv file\n",
    "    contiguity_list.columns = ['Precinct','Neighbors']\n",
    "    district_graph = nx.Graph() #creates an empty undirected graph\n",
    "    district_nodes = assignment[assignment['District']==district_num]['GEOID20'].tolist()\n",
    "    for i in ignore_list:\n",
    "        try:\n",
    "            district_nodes.remove(i)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    district_graph.add_nodes_from(district_nodes)\n",
    "    for id in district_nodes:\n",
    "        neighbors = ast.literal_eval(contiguity_list[contiguity_list['Precinct']==id]['Neighbors'].values.tolist()[0])\n",
    "        # needed to convert string to list because the csv encodes the list as a string\n",
    "        for neighbor in neighbors:\n",
    "            district_graph.add_edge(id,neighbor)\n",
    "    if(print_isolates):\n",
    "        print(list(nx.isolates(district_graph)))\n",
    "    return nx.is_connected(district_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474da28a-35a4-4115-b19e-9439d1044e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistrictPopulations(assignment,data_file, num_district):\n",
    "    population = {}\n",
    "    for i in range (1,num_district+1):\n",
    "        population[i] = data_file[data_file['GEOID20'].isin(assignment[assignment['District']==i]['GEOID20'])]['Total_2020_Total'].sum()\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c27697-04a7-4169-843b-ce2d98622efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistrictShape(district_id, assignment, boundaries):\n",
    "    list_precincts = assignment[assignment['District']==district_id]['GEOID20']\n",
    "    precinct_shapes = []\n",
    "    for i in list_precincts:\n",
    "        if shape(boundaries[i]).type == 'Polygon':\n",
    "            precinct_shapes.append(Polygon(shape(boundaries[i])))\n",
    "        elif shape(boundaries[i]).type == 'MultiPolygon':\n",
    "            precinct_shapes.append(MultiPolygon(shape(boundaries[i])))      \n",
    "    district_shape = shapely.ops.unary_union(precinct_shapes)\n",
    "    #print(district_shape)\n",
    "    return district_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8260f-2f6a-497e-8ff6-51dd9a767180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_compactness(geom): # Polsby-Popper\n",
    "    p = geom.length\n",
    "    a = geom.area    \n",
    "    return (4*np.pi*a)/(p*p)\n",
    "\n",
    "def box_reock_compactness(geom): # Reock on a rectangle bounding box\n",
    "    a = geom.area \n",
    "    bb = geom.bounds # bounds gives you the minimum bounding box (rectangle)\n",
    "    bba = abs(bb[0]-bb[2])*abs(bb[1]-bb[3])\n",
    "    return a/bba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959227a9-93f8-47fa-87ef-02037facafb9",
   "metadata": {},
   "source": [
    "# This Notebook will help you get started on NJ\n",
    "The data is in Canvas, you should upload it to your Google Drive first (if using Colab), or local filesystem (if using Jupyter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69143d08-629d-436a-8687-7a5d3bcb5aa3",
   "metadata": {},
   "source": [
    "### This is the current assignment of precinct to congressional districts (12 of them for NJ)\n",
    "Note that the map shown in DRA is slightly different. This is because some precincts are split in the real assignment, and some additional precinct are created to handle special situations such as prisoners and overseas citizens. You can ignore this for the class project and just use the data and functions provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c2b03-9b2f-46c5-b619-0709ca555c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nj_current_assignment = pd.read_csv('Map_Data/precinct-assignments-congress-nj.csv')\n",
    "nj_current_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6bce06-2f20-4f82-959e-a95f91e25ba5",
   "metadata": {},
   "source": [
    "### This is the current demographic and voter data\n",
    "The data has a lot of attributes that lists voters of different demographics and parties in different elections. You can look at the data Dictionary on Canvas to get details. For this recitation we will only keep votes from the 2020  presidential election and the total 2020 population counts. You can use additional columns (e.g., Governor's elections results, voting age (VAP) population counts, or the composite Dem/Rep score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13a23f-3b65-4852-a42d-3a87867f3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "nj_precinct_data = pd.read_csv('Map_Data/precinct-data-congress-nj.csv')\n",
    "keepcolumns = ['GEOID20','District','Total_2020_Pres','Dem_2020_Pres','Rep_2020_Pres','Total_2020_Total','White_2020_Total','Hispanic_2020_Total','Black_2020_Total','Asian_2020_Total','Native_2020_Total','Pacific_2020_Total']\n",
    "nj_precinct_data = nj_precinct_data[keepcolumns]\n",
    "nj_precinct_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e75d5-6d29-4ab2-ab58-39c67f8b79f1",
   "metadata": {},
   "source": [
    "### This is the precinct boundary data (uses shapely)\n",
    "\n",
    "This is data that represents the geography of the districts. It is needed to test for contiguity, or for any districting partitioning method based on geography. The data is in Shapely format. Each district is represented as a set of points that are connected to create the district shape (in the long/lat coordinates). Shapely geometric functions can be used to compare the shapes. These can be quite inefficient to run, so I am also providing you a pre-computed index that, for each district, lists the districts that are contiguous to it. You can see the code to generate the index in Contiguity.ipynb.\n",
    "\n",
    "To manipulate the shapes, cast them into Shapely Polygons (see example below) and you can use the Polygon properties and functions: https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html#shapely.Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3dbde7-e314-4fe0-9861-969d96e13645",
   "metadata": {},
   "outputs": [],
   "source": [
    "shpfile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.shp'\n",
    "dbffile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.dbf'\n",
    "shxfile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.shx'\n",
    "\n",
    "\n",
    "shpfile = shp.Reader(shp=shpfile, shx=shxfile, dbf=dbffile)\n",
    "nj_precinct_boundaries={}\n",
    "for sr in shpfile.iterShapeRecords():\n",
    "    geom = sr.shape # get geo bit\n",
    "    rec = sr.record # get db fields\n",
    "    nj_precinct_boundaries[rec[3]]=geom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a473b-0936-4c0e-93cc-850329eaa553",
   "metadata": {},
   "source": [
    "### This is the precinct boundary data \n",
    "\n",
    "This use the contiguity index I have pre-computed using Contiguity.ipynb, that is stored in Contiguity_nj.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9f089-caad-45b3-b795-71793bcfedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nj_contiguity = pd.read_csv('Contiguity_nj.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c4cda-bb3c-4392-9df0-5e075c19c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,13):\n",
    "    print(\"District \"+str(i)+\" \"+str(isDistrictContiguous(12, nj_current_assignment, nj_contiguity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bad083-6853-462f-be62-38ff2f84e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compactness of the current assignment\n",
    "for district in range(1,13):\n",
    "    print(\"D\"+str(district)+\" PP : \"+str(pp_compactness(getDistrictShape(district,nj_current_assignment,nj_precinct_boundaries))))\n",
    "    print(\"D\"+str(district)+\" BR : \"+str(box_reock_compactness(getDistrictShape(district,nj_current_assignment,nj_precinct_boundaries))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f2ef1-b4be-4c73-b87a-f6e9f6e9b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# District Population of the current assignment\n",
    "print(getDistrictPopulations(nj_current_assignment,nj_precinct_data, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e696388-313f-4090-9035-09a7da258a19",
   "metadata": {},
   "source": [
    "# A simple geographical  redistricting strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ced817-48c2-4b56-8a46-c274e5b9ff7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can create a simple geopgraphical map, like we did for NH. In this case, we have 12 districts, so let's splitting the district in half North/South, and in 6th  East/West. \n",
    "New Hampshire's bounding box is (-75.559614,38.928519,-73.893979,41.357423) (https://anthonylouisdagostino.com/bounding-boxes-for-all-us-states/)\n",
    "So let's start by splitting the state approximately though the middle longitude (-74.72) : everything west of longitude -71.583934 is in odd Districts, everything east is in even Districts. We will use the precinct centroids to assign them. Then we will divide each half per latitude on the ranges  (38.92, 39.3, 39.7, 40.1, 40.5,40.9,41.35)\n",
    "Import the Map to DRA to look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da30c782-b466-47d7-bb37-78b3cad6bd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nj_longlat_assignment = nj_current_assignment.copy()\n",
    "nj_longlat_assignment['District'] = 0\n",
    "for index, row in nj_longlat_assignment.iterrows():\n",
    "    try:\n",
    "        if shape(nj_precinct_boundaries[row['GEOID20']]).type == 'Polygon':\n",
    "            centroid = Polygon(shape(nj_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        elif shape(nj_precinct_boundaries[row['GEOID20']]).type == 'MultiPolygon':\n",
    "            centroid = MultiPolygon(shape(nj_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        else:\n",
    "            print(shape(nj_precinct_boundaries[row['GEOID20']]).type)\n",
    "            pass\n",
    "        if centroid.x <= -74.72:\n",
    "            if centroid.y <= 39.3:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 1\n",
    "            elif centroid.y <= 39.7:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 3\n",
    "            elif centroid.y <= 40.1:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 5\n",
    "            elif centroid.y <= 40.5:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 7\n",
    "            elif centroid.y <= 40.9:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 9\n",
    "            else:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 11\n",
    "        else:\n",
    "            if centroid.y <= 39.3:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 2\n",
    "            elif centroid.y <= 39.7:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 4\n",
    "            elif centroid.y <= 40.1:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 6\n",
    "            elif centroid.y <= 40.5:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 8\n",
    "            elif centroid.y <= 40.9:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 10\n",
    "            else:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 12\n",
    "    except KeyError: \n",
    "        pass\n",
    "#print(nh_longitude_assignment)\n",
    "nj_longlat_assignment.to_csv('Recitation maps/nj_longlat_map.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00508f-3df2-487c-90ac-56a7af050c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compactness of this Longlat assignment\n",
    "for district in range(1,13):\n",
    "    print(\"D\"+str(district)+\" PP : \"+str(pp_compactness(getDistrictShape(district,nj_longlat_assignment,nj_precinct_boundaries))))\n",
    "    print(\"D\"+str(district)+\" BR : \"+str(box_reock_compactness(getDistrictShape(district,nj_longlat_assignment,nj_precinct_boundaries))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c674a-6122-4440-a87a-9b5b4250f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# District Population of this longlat assignment\n",
    "print(getDistrictPopulations(nj_longlat_assignment,nj_precinct_data, 12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f943977-f3a0-41b8-930e-6e26d74092f2",
   "metadata": {},
   "source": [
    "# Now create your own redistricting maps\n",
    "Remember to check for contiguity, and to ensure that the population of the districts are balanced (which is not the case in the example above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Existing Map - Flip Step\n",
    "random based strategy similar to one in recitation_redistricting notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65fda189-958e-4639-8c9e-78d618ea055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous code not functionl\n",
    "#import random\n",
    "\n",
    "# nj_flip_assignment = nj_current_assignment.copy()\n",
    "\n",
    "# D1_Border_precincts = [] #NJ has 12 districts, and there should be 6361 precincts (rows)\n",
    "# D1_list = nj_flip_assignment[nj_flip_assignment['District']==1]['GEOID20'].tolist()\n",
    "\n",
    "\n",
    "# for precinct in D1_list: \n",
    "#     neighbors = nj_contiguity[nj_contiguity['GEOID20']==precinct]['Neighbor'].tolist()\n",
    "#     for neighbor in neighbors:\n",
    "#         if nj_flip_assignment[nj_flip_assignment['GEOID20']==neighbor]['District'].tolist()[0] == 2:\n",
    "#             #if one of the neighbor is in D2, then this is a border district\n",
    "#             D1_Border_precincts.append(precinct)\n",
    "#             break\n",
    "\n",
    "# # calculate percenage of total number of precincts\n",
    "# num_precincts_to_flip = int(len(D1_list) * 0.15)\n",
    "\n",
    "# for i in range(10):\n",
    "#     precinct_to_flip = np.random.choice(D1_Border_precincts)\n",
    "#     nj_flip_assignment.loc[nj_flip_assignment['GEOID20']==precinct_to_flip, 'District'] = 2\n",
    "#     if not isDistrictContiguous(nj_flip_assignment, 1) or not isDistrictContiguous(nj_flip_assignment, 2):\n",
    "#         nj_flip_assignment.loc[nj_flip_assignment['GEOID20']==precinct_to_flip, 'District'] = 1\n",
    "#         print(\"Contiguity was broken, precinct was reassigned back to D1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nj_flipstep_assignment = nj_current_assignment.copy()\n",
    "\n",
    "## simplistic approach\n",
    "## we randomly select 10 D1 precincts that border D2 and assign them to D2\n",
    "\n",
    "D1_border_precincts = []\n",
    "\n",
    "D1_list = nj_longlat_assignment[nj_longlat_assignment['District']==1]['GEOID20']\n",
    "for precinct in D1_list:\n",
    "    neighbors = ast.literal_eval(nj_contiguity[nj_contiguity['Precinct']==precinct]['Neighbors'].values.tolist()[0])\n",
    "    for neighbor in neighbors:\n",
    "        if nj_flipstep_assignment.loc[nj_flipstep_assignment['GEOID20']==neighbor,'District'].values.tolist()[0]==2:\n",
    "            #if one of the neighbor is in D2, then this is a border district\n",
    "            D1_border_precincts.append(precinct)\n",
    "            break\n",
    "\n",
    "#Sample 10 and flip them UNLESS it breaks contiguity\n",
    "flipped_precincts = np.random.choice(D1_border_precincts,10)\n",
    "for flip in flipped_precincts:\n",
    "    nj_flipstep_assignment.loc[nj_flipstep_assignment['GEOID20']==flip,'District']=2\n",
    "    #check if we broke contiguity and revert the flip if we did\n",
    "    if(isDistrictContiguous(1,nj_flipstep_assignment,nj_contiguity) is False or isDistrictContiguous(2,nj_flipstep_assignment,nj_contiguity) is False):\n",
    "        nj_flipstep_assignment.loc[nj_flipstep_assignment['GEOID20']==flip,'District']=1\n",
    "        print(\"Contiguity broken \" + flip)\n",
    "\n",
    "# First we randomly select 10 DIFFERENT D2 precincts that border D1 and assign them to D1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfair Map\n",
    "map should be designed to give a party/community/area some advantage (unfair map) using some creative gerrymandering techniques. The less likely the map would be to be thrown out of courts for obvious gerrymandering, the better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
